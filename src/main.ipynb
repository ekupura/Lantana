{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from captum.attr import *\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)solve/main/vocab.txt: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 686kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 4.77kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 570/570 [00:00<00:00, 426kB/s]\n",
      "Downloading builder script: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.31k/4.31k [00:00<00:00, 9.93MB/s]\n",
      "Downloading metadata: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.17k/2.17k [00:00<00:00, 7.10MB/s]\n",
      "Downloading readme: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7.59k/7.59k [00:00<00:00, 15.6MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset imdb/plain_text to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84.1M/84.1M [00:18<00:00, 4.62MB/s]\n",
      "                                                                                                                                                                                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset imdb downloaded and prepared to /root/.cache/huggingface/datasets/imdb/plain_text/1.0.0/d613c88cf8fa3bab83b4ded3713f1f74830d1100e171db75bbddb80b3345c9c0. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 450.78it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "# Load the IMDB dataset\n",
    "import datasets\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the IMDB dataset\n",
    "train_dataset, test_dataset = datasets.load_dataset('imdb', split=['train', 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset[:1000]\n",
    "test_dataset = test_dataset[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the texts\n",
    "train_encodings = tokenizer(train_dataset['text'], truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_dataset['text'], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to tensors\n",
    "train_labels = torch.tensor(train_dataset['label'])\n",
    "test_labels = torch.tensor(test_dataset['label'])\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(\n",
    "    torch.tensor(train_encodings['input_ids']),\n",
    "    torch.tensor(train_encodings['attention_mask']),\n",
    "    train_labels\n",
    ")\n",
    "\n",
    "test_dataset = TensorDataset(\n",
    "    torch.tensor(test_encodings['input_ids']),\n",
    "    torch.tensor(test_encodings['attention_mask']),\n",
    "    test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading pytorch_model.bin: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 440M/440M [00:38<00:00, 11.5MB/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# BERTモデルを読み込む\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:15<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1535117942839861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01300091047596652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005507391368155368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003547344902472105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0025777295959414914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018891148465627339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0014284843346104026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001109989427277469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008749525168241234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:14<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006993858769419603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# データローダーを作成する\n",
    "batch_size = 32  # 適宜調整する\n",
    "train_dataset\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# オプティマイザーを設定する\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# モデルを訓練する\n",
    "num_epochs = 10  # 適宜調整する\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids = batch[0].to(model.device).cuda()\n",
    "        attention_masks = batch[1].to(model.device).cuda()\n",
    "        labels = batch[2].to(model.device).cuda()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_masks,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME の基本実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "class Lime:\n",
    "    def __init__(self, predict_fn, perturb_fn, kernel_width=0.75):\n",
    "        self.predict_fn = predict_fn\n",
    "        self.perturb_fn = perturb_fn\n",
    "        self.kernel_width = kernel_width\n",
    "\n",
    "    def explain_instance(self, instance, use_weights=True):\n",
    "        # Step 1: Generate random samples around the instance\n",
    "        samples = self.perturb_fn(instance)\n",
    "\n",
    "        # Step 2: Get predictions for the samples using the black-box model\n",
    "        predictions = [self.predict_fn(sample) for sample in tqdm(samples)]\n",
    "\n",
    "        if use_weights:\n",
    "            # Step 3: Compute distances between the instance and the samples\n",
    "            distances = self._compute_distances(instance, samples)\n",
    "            # Step 4: Compute weights using kernel function\n",
    "            weights = self._kernel(distances)\n",
    "        else:\n",
    "            weights = np.ones(samples.shape[0])\n",
    "\n",
    "        # Step 5: Fit a linear model using the samples and predictions\n",
    "        model = Ridge(alpha=1.0)\n",
    "        model.fit(samples, predictions, sample_weight=weights)\n",
    "\n",
    "        return model.coef_\n",
    "\n",
    "    def _compute_distances(self, instance, samples):\n",
    "        return np.linalg.norm(samples - instance, axis=1)\n",
    "\n",
    "    def _kernel(self, distances):\n",
    "        return np.exp(-distances / self.kernel_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def additive_fn(instance, num_samples=1000):\n",
    "    samples = np.random.normal(0, 1, (num_samples, instance.shape[0]))\n",
    "    return samples + instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perturb_fn(instance, num_samples=1000, perturb_size=1):\n",
    "    mask_array = []\n",
    "    for _ in range(num_samples):\n",
    "        row = [1.0 if idx >= perturb_size else 0.0 for idx in range(instance.shape[0])]\n",
    "        mask_array.append(np.random.permutation(row))\n",
    "    mask_array = np.array(mask_array)\n",
    "    return mask_array * instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_fn = lambda x: perturb_fn(x, perturb_size=1)\n",
    "suff_fn = lambda x: perturb_fn(x, perturb_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a black-box model\n",
    "def black_box_model(array):\n",
    "    predictions = array[0] + array[1] * 2 + array[2] * 3\n",
    "    predictions = array[3] ** 2 + array[4] ** 3\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ベースライン実験\n",
    "動作確認兼ベースライン生成のコード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 298569.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.10577409 0.06916762 0.12131477 1.94136409 4.68235533]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Explain an instance\n",
    "instance = np.array([1, 1, 1, 1, 1])\n",
    "# Create an instance of LIME\n",
    "lime = Lime(predict_fn=black_box_model, perturb_fn=additive_fn)\n",
    "explanation = lime.explain_instance(instance, use_weights=True)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faithfulness実験\n",
    "ここで解釈モデルが Faithfulness を予測するモデルになっているはず..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 502853.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.39294367 -0.39216856 -0.39239663  0.58889633  0.58861254]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Explain an instance\n",
    "instance = np.array([1, 1, 1, 1, 1])\n",
    "# Create an instance of LIME\n",
    "lime = Lime(predict_fn=black_box_model, perturb_fn=comp_fn)\n",
    "explanation = lime.explain_instance(instance, use_weights=True)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT でやってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_embedding(sample):\n",
    "    ids, mask = sample[0].unsqueeze(0).cuda(), sample[1].unsqueeze(0).cuda()\n",
    "    embedding = model.bert.embeddings(input_ids=ids)\n",
    "    return embedding.cpu().squeeze(0).detach().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(array):\n",
    "    array = array.reshape(-1, 768)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_wrapper(instance):\n",
    "    reshaped = reshape(instance)\n",
    "    with torch.no_grad():\n",
    "        reshaped = torch.tensor(reshaped).unsqueeze(0).cuda().to(torch.float32)\n",
    "        prediction = model(inputs_embeds=reshaped)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                                                                                                                                                | 0/1000 [00:00<?, ?it/s]\u001B[A\n",
      "  1%|██▍                                                                                                                                                                                                   | 12/1000 [00:00<00:08, 111.02it/s]\u001B[A\n",
      "  2%|████▊                                                                                                                                                                                                 | 24/1000 [00:00<00:08, 108.64it/s]\u001B[A\n",
      " 51%|████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                                                 | 507/1000 [00:19<00:05, 97.99it/s]\u001B[A\n",
      "  5%|█████████▌                                                                                                                                                                                            | 48/1000 [00:00<00:08, 113.43it/s]\u001B[A\n",
      "  6%|███████████▉                                                                                                                                                                                          | 60/1000 [00:00<00:08, 105.59it/s]\u001B[A\n",
      "  7%|██████████████                                                                                                                                                                                        | 71/1000 [00:00<00:08, 104.07it/s]\u001B[A\n",
      "  8%|████████████████▎                                                                                                                                                                                      | 82/1000 [00:00<00:09, 92.72it/s]\u001B[A\n",
      "  9%|██████████████████▎                                                                                                                                                                                    | 92/1000 [00:00<00:09, 91.40it/s]\u001B[A\n",
      " 10%|████████████████████▌                                                                                                                                                                                 | 104/1000 [00:01<00:09, 98.18it/s]\u001B[A\n",
      " 11%|██████████████████████▌                                                                                                                                                                               | 114/1000 [00:01<00:09, 95.22it/s]\u001B[A\n",
      " 12%|████████████████████████▊                                                                                                                                                                             | 125/1000 [00:01<00:08, 98.80it/s]\u001B[A\n",
      " 14%|██████████████████████████▉                                                                                                                                                                          | 137/1000 [00:01<00:08, 102.64it/s]\u001B[A\n",
      " 15%|█████████████████████████████▎                                                                                                                                                                       | 149/1000 [00:01<00:08, 106.29it/s]\u001B[A\n",
      " 16%|███████████████████████████████▋                                                                                                                                                                     | 161/1000 [00:01<00:07, 108.51it/s]\u001B[A\n",
      " 17%|█████████████████████████████████▉                                                                                                                                                                   | 172/1000 [00:01<00:08, 102.00it/s]\u001B[A\n",
      " 18%|████████████████████████████████████▏                                                                                                                                                                | 184/1000 [00:01<00:07, 102.66it/s]\u001B[A\n",
      " 20%|██████████████████████████████████████▌                                                                                                                                                              | 196/1000 [00:01<00:07, 106.01it/s]\u001B[A\n",
      " 21%|████████████████████████████████████████▉                                                                                                                                                            | 208/1000 [00:02<00:07, 107.66it/s]\u001B[A\n",
      " 22%|███████████████████████████████████████████▏                                                                                                                                                         | 219/1000 [00:02<00:07, 105.94it/s]\u001B[A\n",
      " 23%|█████████████████████████████████████████████▌                                                                                                                                                       | 231/1000 [00:02<00:07, 108.55it/s]\u001B[A\n",
      " 24%|███████████████████████████████████████████████▊                                                                                                                                                     | 243/1000 [00:02<00:06, 110.35it/s]\u001B[A\n",
      " 26%|██████████████████████████████████████████████████▍                                                                                                                                                   | 255/1000 [00:02<00:07, 99.83it/s]\u001B[A\n",
      " 27%|████████████████████████████████████████████████████▍                                                                                                                                                | 266/1000 [00:02<00:07, 101.54it/s]\u001B[A\n",
      " 28%|██████████████████████████████████████████████████████▊                                                                                                                                               | 277/1000 [00:02<00:07, 94.39it/s]\u001B[A\n",
      " 29%|█████████████████████████████████████████████████████████                                                                                                                                             | 288/1000 [00:02<00:07, 98.40it/s]\u001B[A\n",
      " 30%|███████████████████████████████████████████████████████████▏                                                                                                                                          | 299/1000 [00:02<00:07, 97.51it/s]\u001B[A\n",
      " 31%|█████████████████████████████████████████████████████████████                                                                                                                                        | 310/1000 [00:03<00:06, 100.27it/s]\u001B[A\n",
      " 32%|███████████████████████████████████████████████████████████████▏                                                                                                                                     | 321/1000 [00:03<00:06, 102.29it/s]\u001B[A\n",
      " 33%|█████████████████████████████████████████████████████████████████▌                                                                                                                                   | 333/1000 [00:03<00:06, 105.68it/s]\u001B[A\n",
      " 34%|███████████████████████████████████████████████████████████████████▉                                                                                                                                 | 345/1000 [00:03<00:06, 107.95it/s]\u001B[A\n",
      " 36%|██████████████████████████████████████████████████████████████████████▏                                                                                                                              | 356/1000 [00:03<00:06, 100.36it/s]\u001B[A\n",
      " 37%|████████████████████████████████████████████████████████████████████████▋                                                                                                                             | 367/1000 [00:03<00:06, 96.82it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████████████████████████████████████████████████████████▋                                                                                                                          | 379/1000 [00:03<00:06, 101.82it/s]\u001B[A\n",
      " 39%|█████████████████████████████████████████████████████████████████████████████                                                                                                                        | 391/1000 [00:03<00:05, 105.54it/s]\u001B[A\n",
      " 40%|███████████████████████████████████████████████████████████████████████████████▍                                                                                                                     | 403/1000 [00:03<00:05, 107.78it/s]\u001B[A\n",
      " 42%|█████████████████████████████████████████████████████████████████████████████████▊                                                                                                                   | 415/1000 [00:04<00:05, 108.90it/s]\u001B[A\n",
      " 43%|████████████████████████████████████████████████████████████████████████████████████                                                                                                                 | 427/1000 [00:04<00:05, 110.83it/s]\u001B[A\n",
      " 44%|██████████████████████████████████████████████████████████████████████████████████████▍                                                                                                              | 439/1000 [00:04<00:05, 111.19it/s]\u001B[A\n",
      " 45%|████████████████████████████████████████████████████████████████████████████████████████▊                                                                                                            | 451/1000 [00:04<00:05, 107.80it/s]\u001B[A\n",
      " 46%|███████████████████████████████████████████████████████████████████████████████████████████                                                                                                          | 462/1000 [00:04<00:05, 104.59it/s]\u001B[A\n",
      " 47%|█████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                        | 473/1000 [00:04<00:05, 92.52it/s]\u001B[A\n",
      " 48%|███████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                                      | 483/1000 [00:04<00:05, 92.18it/s]\u001B[A\n",
      " 49%|█████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                                    | 493/1000 [00:04<00:05, 93.79it/s]\u001B[A\n",
      " 50%|███████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                                  | 505/1000 [00:04<00:04, 99.80it/s]\u001B[A\n",
      " 52%|█████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                                               | 517/1000 [00:05<00:04, 104.67it/s]\u001B[A\n",
      " 53%|████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                                            | 529/1000 [00:05<00:04, 107.61it/s]\u001B[A\n",
      " 54%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                                                          | 541/1000 [00:05<00:04, 109.67it/s]\u001B[A\n",
      " 55%|████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                                        | 553/1000 [00:05<00:04, 105.97it/s]\u001B[A\n",
      " 56%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                                     | 565/1000 [00:05<00:04, 108.46it/s]\u001B[A\n",
      " 58%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                                   | 577/1000 [00:05<00:03, 110.38it/s]\u001B[A\n",
      " 59%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                                                 | 589/1000 [00:05<00:03, 111.32it/s]\u001B[A\n",
      " 60%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                              | 601/1000 [00:05<00:03, 112.15it/s]\u001B[A\n",
      " 61%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                            | 613/1000 [00:05<00:03, 112.74it/s]\u001B[A\n",
      " 62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                                         | 625/1000 [00:05<00:03, 113.11it/s]\u001B[A\n",
      " 64%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                       | 637/1000 [00:06<00:03, 112.19it/s]\u001B[A\n",
      " 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                     | 649/1000 [00:06<00:03, 108.76it/s]\u001B[A\n",
      " 66%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                   | 660/1000 [00:06<00:03, 90.17it/s]\u001B[A\n",
      " 67%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                 | 670/1000 [00:06<00:03, 87.17it/s]\u001B[A\n",
      " 68%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                               | 680/1000 [00:06<00:03, 83.07it/s]\u001B[A\n",
      " 69%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                             | 690/1000 [00:06<00:03, 86.94it/s]\u001B[A\n",
      " 70%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                                           | 701/1000 [00:06<00:03, 92.90it/s]\u001B[A\n",
      " 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                         | 712/1000 [00:06<00:03, 95.90it/s]\u001B[A\n",
      " 72%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                      | 724/1000 [00:07<00:02, 100.38it/s]\u001B[A\n",
      " 74%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                                    | 735/1000 [00:07<00:02, 96.53it/s]\u001B[A\n",
      " 75%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                                                 | 747/1000 [00:07<00:02, 101.09it/s]\u001B[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                                               | 759/1000 [00:07<00:02, 104.38it/s]\u001B[A\n",
      " 77%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                             | 770/1000 [00:07<00:02, 99.79it/s]\u001B[A\n",
      " 78%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                           | 782/1000 [00:07<00:02, 103.26it/s]\u001B[A\n",
      " 79%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                        | 794/1000 [00:07<00:01, 105.82it/s]\u001B[A\n",
      " 81%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                      | 806/1000 [00:07<00:01, 107.40it/s]\u001B[A\n",
      " 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                    | 817/1000 [00:07<00:01, 107.53it/s]\u001B[A\n",
      " 83%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                  | 828/1000 [00:08<00:01, 105.85it/s]\u001B[A\n",
      " 84%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                               | 840/1000 [00:08<00:01, 107.29it/s]\u001B[A\n",
      " 85%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                             | 851/1000 [00:08<00:01, 97.76it/s]\u001B[A\n",
      " 86%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 861/1000 [00:08<00:01, 94.64it/s]\u001B[A\n",
      " 87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                         | 871/1000 [00:08<00:01, 87.52it/s]\u001B[A\n",
      " 88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                       | 881/1000 [00:08<00:01, 89.33it/s]\u001B[A\n",
      " 89%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                     | 893/1000 [00:08<00:01, 95.92it/s]\u001B[A\n",
      " 90%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                  | 905/1000 [00:08<00:00, 100.74it/s]\u001B[A\n",
      " 92%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                | 917/1000 [00:08<00:00, 103.98it/s]\u001B[A\n",
      " 93%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊              | 928/1000 [00:09<00:00, 102.81it/s]\u001B[A\n",
      " 94%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉            | 939/1000 [00:09<00:00, 104.25it/s]\u001B[A\n",
      " 95%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎         | 951/1000 [00:09<00:00, 105.91it/s]\u001B[A\n",
      " 96%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋       | 963/1000 [00:09<00:00, 107.60it/s]\u001B[A\n",
      " 98%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████     | 975/1000 [00:09<00:00, 108.94it/s]\u001B[A\n",
      " 99%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏  | 986/1000 [00:09<00:00, 106.49it/s]\u001B[A\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:09<00:00, 102.30it/s]\u001B[A\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'SequenceClassifierOutput'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_396/2890385331.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0minstance\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mto_embedding\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_dataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mlime\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpredict_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbert_wrapper\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mperturb_fn\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0madditive_fn\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mexplanation\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexplain_instance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minstance\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0muse_weights\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexplanation\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_396/3445039301.py\u001B[0m in \u001B[0;36mexplain_instance\u001B[0;34m(self, instance, use_weights)\u001B[0m\n\u001B[1;32m     25\u001B[0m         \u001B[0;31m# Step 5: Fit a linear model using the samples and predictions\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     26\u001B[0m         \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRidge\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0malpha\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1.0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 27\u001B[0;31m         \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msamples\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mweights\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     29\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcoef_\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    760\u001B[0m         \u001B[0mself\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mreturns\u001B[0m \u001B[0man\u001B[0m \u001B[0minstance\u001B[0m \u001B[0mof\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    761\u001B[0m         \"\"\"\n\u001B[0;32m--> 762\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    763\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    764\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_ridge.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    540\u001B[0m         _accept_sparse = _get_valid_accept_sparse(sparse.issparse(X),\n\u001B[1;32m    541\u001B[0m                                                   self.solver)\n\u001B[0;32m--> 542\u001B[0;31m         X, y = self._validate_data(X, y,\n\u001B[0m\u001B[1;32m    543\u001B[0m                                    \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_accept_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    544\u001B[0m                                    \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0m_dtype\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    431\u001B[0m                 \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    432\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 433\u001B[0;31m                 \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    434\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    435\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/opt/conda/lib/python3.8/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m    884\u001B[0m         \u001B[0m_assert_all_finite\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    885\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0my_numeric\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m'O'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 886\u001B[0;31m         \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mastype\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    887\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m     \u001B[0mcheck_consistent_length\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: float() argument must be a string or a number, not 'SequenceClassifierOutput'"
     ]
    }
   ],
   "source": [
    "instance = to_embedding(train_dataset[0])\n",
    "lime = Lime(predict_fn=bert_wrapper, perturb_fn=additive_fn)\n",
    "explanation = lime.explain_instance(instance, use_weights=True)\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
